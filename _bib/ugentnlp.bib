
@article{Demeester18_sparseness,
 title={Predefined Sparseness in Recurrent Sequence Models},
 author={Demeester, Thomas and Deleu, Johannes and Godin, Frederic and Develder, Chris},
 journal={Proc. The SIGNLL Conference on Computational Natural Language Learning (CoNLL)},
 year={2018},
 abstract = {Inducing sparseness while training neural networks has been shown to yield models with a lower memory footprint but similar effectiveness to dense models. However, sparseness is typically induced starting from a dense model, and thus this advantage does not hold during training. We propose techniques to enforce sparseness upfront in recurrent sequence models for NLP applications, to also benefit training. First, in language modeling, we show how to increase hidden state sizes in recurrent layers without increasing the number of parameters, leading to more expressive models. Second, for sequence labeling, we show that word embeddings with predefined sparseness lead to similar performance as dense embeddings, at a fraction of the number of trainable parameters.},
}

@article{Godin18_decomposition,
 title={Explaining Character-Aware Neural Networks for Word-Level Prediction: Do They Discover Linguistic Rules?},
 author={Godin, Frederic and Demuynck, Kris and Dambre, Joni and De Neve, Wesley and Demeester, Thomas},
 journal={Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP 2018)},
 year={2018}
}

@article{Bekoulis18_advtraining,
 title={Adversarial training for multi-context joint entity and relation extraction},
 author={Bekoulis, Giannis and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
 journal={Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP 2018)},
 year={2018},
 abstract = {Adversarial training (AT) is a regularization method that can be used to improve the robustness of neural network methods by adding small perturbations in the training data. We show how to use AT for the tasks of entity recognition and relation extraction. In particular, we demonstrate that applying AT to a general purpose baseline model for jointly extracting entities and relations, allows improving the state-of-the-art effectiveness on several datasets in different contexts (i.e., news, biomedical, and real estate data) and for different languages (English and Dutch).},
}


@article{Bekoulis18_multi_head,
 title={Joint entity recognition and relation extraction as a multi-head selection problem},
  author={Bekoulis, Giannis and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
journal={Expert Systems with Applications},
url={https://arxiv.org/abs/1804.07847v1},
year={2018},
pdf={https://arxiv.org/pdf/1804.07847v1.pdf},
pubtype={a1},
abstract = {State-of-the-art models for joint entity recognition and relation extraction strongly rely on external natural language processing (NLP) tools such as POS (part-of-speech) taggers and dependency parsers. Thus, the performance of such joint models depends on the quality of the features obtained from these NLP tools. However, these features are not always accurate for various languages and contexts. In this paper, we propose a joint neural model which performs entity recognition and relation extraction simultaneously, without the need of any manually extracted features or the use of any external tool. Specifically, we model the entity recognition task using a CRF (Conditional Random Fields) layer and the relation extraction task as a multi-head selection problem (i.e., potentially identify multiple relations for each entity). We present an extensive experimental setup, to demonstrate the effectiveness of our method using datasets from various contexts (i.e., news, biomedical, real estate) and languages (i.e., English, Dutch). Our model outperforms the previous neural models that use automatically extracted features, while it performs within a reasonable margin of feature-based neural models, or even beats them.},
}


@article{Deboom18_rnn,
author = {De Boom, Cedric and Demeester, Thomas and Dhoedt, Bart},
journal      = {Neural Computing and Applications},
title = {Character-level Recurrent Neural Networks in Practice: Comparing Training and Sampling Schemes},
year = {2018},
pdf = {https://arxiv.org/pdf/1801.00632.pdf},
data = {https://github.com/cedricdeboom/character-level-rnn-datasets},
pubtype={a1}
}


@inproceedings{Weissenborn18_jtr,
title = {Jack the Reader -- A Machine Reading Framework},
author = {Weissenborn, Dirk and Minervine, Pasquale and Dettmers, Tim and Augenstein, Isabelle and Welbl, Johannes and Rockt{\"a}schel, Tim and Bo\v{s}njak, Matko and Mitchell, Jeff and Demeester, Thomas and Stenetorp, Pontus and Riedel, Sebastian},
booktitle = {Proc. 56th Annual Meeting of the Association for Computational Linguistics (Demos track)},
year = {2018},
code = {https://github.com/uclmr/jack},
pdf = {https://arxiv.org/pdf/1806.08727}
}


@inproceedings{zaporojets2018clpsych,
author = {Zaporojets, Klim and Lucas Sterckx and Johannes Deleu and Thomas Demeester and Chris Develder},
title = {Predicting psychological health from childhood essays: The UGent-IDLab CLPsych 2018 shared task system},
booktitle = {Proc. 5th Ann. Workshop on Comput. Linguistics and Clinical Psychology (CLPsych 2018) at NAACL-HLT 2018},
month = {5 Jun.},
year = {2018},
address = {New Orleans, LA, USA},
pdf = {https://biblio.ugent.be/publication/8567169/file/8567171.pdf}
}


@inproceedings{Sterckx18_priorattention,
title={Prior Attention for Style-aware Sequence-to-Sequence Models},
author={Sterckx, Lucas and Deleu, Johannes and Develder, Chris and Demeester, Thomas},
year={2018},
booktitle={arXiv preprint},
pdf={https://arxiv.org/pdf/1806.09439.pdf}
}


@article{Bekoulis18_journal1,
  abstract     = {In processing human produced text using natural language processing (NLP) techniques, two fundamental subtasks that arise are (i) segmentation of the plain text into meaningful subunits (e.g., entities), and (ii) dependency parsing, to establish relations between subunits. Such structural interpretation of text provides essential building blocks for upstream expert system tasks: e.g., from interpreting textual real estate ads, one may want to provide an accurate price estimate and/or provide selection filters for end users looking for a particular property - which all could rely on knowing the types and number of rooms, etc. In this paper, we develop a relatively simple and effective neural joint model that performs both segmentation and dependency parsing together, instead of one after the other as in most state-of-the-art works. We will focus in particular on the real estate ad setting, aiming to convert an ad to a structured description, which we name property tree, comprising the tasks of (1) identifying important entities of a property (e.g., rooms) from classifieds and (2) structuring them into a tree format. In this work, we propose a new joint model that is able to tackle the two tasks simultaneously and construct the property tree by (i) avoiding the error propagation that would arise from the subtasks one after the other in a pipelined fashion, and (ii) exploiting the interactions between the subtasks. For this purpose, we perform an extensive comparative study of the pipeline methods and the new proposed joint model, reporting an improvement of over three percentage points in the overall edge F-1 score of the property tree. Also, we propose attention methods, to encourage our model to focus on salient tokens during the construction of the property tree. Thus we experimentally demonstrate the usefulness of attentive neural architectures for the proposed joint model, showcasing a further improvement of two percentage points in edge F-1 score for our application. While the results demonstrated are for the particular real estate setting, the model is generic in nature, and thus could be equally applied to other expert system scenarios requiring the general tasks of both (i) detecting entities (segmentation) and (ii) establishing relations among them (dependency parsing). (C) 2018 Elsevier Ltd. All rights reserved.},
  author       = {Bekoulis, Giannis and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
  issn         = {0957-4174},
  journal      = {Expert Systems with Applications},
  keyword      = {NAMED ENTITY RECOGNITION,EXTRACTION,NETWORKS,Neural networks,Joint model,Relation extraction,Entity recognition,Dependency parsing},
  language     = {eng},
  pages        = {100--112},
  publisher    = {Pergamon-elsevier Science Ltd},
  title        = {An attentive neural architecture for joint segmentation and parsing and its application to real estate ads},
  url          = {http://dx.doi.org/10.1016/j.eswa.2018.02.031},
  volume       = {102},
  year         = {2018},
  pdf = {https://arxiv.org/pdf/1709.09590},
  url = {https://dl.acm.org/citation.cfm?id=3199179},
  pubtype={a1}
}


@Article{Sterckx18_keyphrasecollection,
author="Sterckx, Lucas
and Demeester, Thomas
and Deleu, Johannes
and Develder, Chris",
title="Creation and evaluation of large keyphrase extraction collections with multiple opinions",
journal="Language Resources and Evaluation",
year="2018",
month="Jul.",
day="01",
volume="52",
number="2",
pages="503--532",
issn="1574-0218",
doi="10.1007/s10579-017-9395-6",
pdf = {https://biblio.ugent.be/publication/8563585/file/8563587.pdf},
url = {https://link.springer.com/article/10.1007/s10579-017-9395-6},
pubtype={a1},
abstract ={While several Automatic Keyphrase Extraction (AKE) techniques have been developed and analyzed, there is little consensus on the definition of the task and a lack of overview of the effectiveness of different techniques. Proper evaluation of keyphrase extraction requires large test collections with multiple opinions, currently not available for research. In this paper, we (i) present a set of test collections derived from various sources with multiple annotations (which we also refer to as opinions in the remained of the paper) for each document, (ii) systematically evaluate keyphrase extraction using several supervised and unsupervised AKE techniques, (iii) and experimentally analyze the effects of disagreement on AKE evaluation. Our newly created set of test collections spans different types of topical content from general news and magazines, and is annotated with multiple annotations per article by a large user panel. Our user study shows that for a given document there seems to be a large disagreement on the preferred keyphrases, suggesting the need for multiple opinions per document. A first systematic evaluation of ranking and classification of keyphrases using both unsupervised and supervised AKE techniques on the test collections shows a superior effectiveness of supervised models, even for a low annotation effort and with basic positional and frequency features, and highlights the importance of a suitable keyphrase candidate generation approach. We also study the influence of multiple opinions, training data and document length on evaluation of keyphrase extraction. Our new test collection for keyphrase extraction is one of the largest of its kind and will be made available to stimulate future work to improve reliable evaluation of new keyphrase extractors.}, 
}

@article{Vancanneyt18_providence,
  abstract     = {As the market of globally available online news is large and still growing, there is a strong competition between online publishers in order to reach the largest possible audience. Therefore an intelligent online publishing strategy is of the highest importance to publishers. A prerequisite for being able to optimize any online strategy, is to have trustworthy predictions of how popular new online content may become. This paper presents a novel methodology to model and predict the popularity of online news. We first introduce a new strategy and mathematical model to capture view patterns of online news. After a thorough analysis of such view patterns, we show that well-chosen base functions lead to suitable models, and show how the influence of day versus night on the total view patterns can be taken into account to further increase the accuracy, without leading to more complex models. Second, we turn to the prediction of future popularity, given recently published content. By means of a new real-world dataset, we show that the combination of features related to content, meta-data, and the temporal behavior leads to significantly improved predictions, compared to existing approaches which only consider features based on the historical popularity of the considered articles. Whereas traditionally linear regression is used for the application under study, we show that the more expressive gradient tree boosting method proves beneficial for predicting news popularity.},
  author       = {Van Canneyt, Steven and Leroux, Philip and Dhoedt, Bart and Demeester, Thomas},
  issn         = {1380-7501},
  journal      = {Multimedia Tools and Applications},
  keyword      = {IBCN,Online news,Popularity modeling,Popularity prediction,Regression,Feature engineering},
  language     = {eng},
  number       = {1},
  pages        = {1409--1436},
  publisher    = {Springer},
  title        = {Modeling and predicting the popularity of online news based on temporal and content-related features},
  url          = {https://link.springer.com/article/10.1007/s11042-017-4348-z},
  volume       = {77},
  year         = {2018},
  pdf = {https://biblio.ugent.be/publication/8547204/file/8547206.pdf},
  pubtype={a1}
}

@article{Deygers18,
  abstract     = {In Flanders, Belgium, university admission of undergraduate international L2 students requires a certificate of an accredited test of Dutch. The two main university entrance tests used for certification share highly comparable oral components and CEFR-based oral rating criteria. This article discusses to what extent ratings on the oral components of these tests can be compared. The data used are the ratings of the oral performances of the same 82 candidates on both oral test components, which were administered within the same week. The correlation on the overall scores is high, but lower on the oral test component. Further analyses, including linear regression and multifaceted Rasch analysis, indicate that the B2 level was interpreted differently in the two tests. The results show that using the same language proficiency scales as the basis for rating scale criteria may lead to superficial correspondences or a perceived equivalence but does not necessarily lead to greater comparability of shared criteria. The findings of this study are especially useful for contexts in which different tests use similar criteria that are based on the same descriptors, and comparability is only assumed.},
  author       = {Deygers, Bart and Van Gorp, Koen and Demeester, Thomas},
  issn         = {1543-4303},
  journal      = {Language Assessment Quarterly},
  number       = {1},
  pages        = {44--58},
  title        = {The {B}2 Level and the Dream of a Common Standard},
  url          = {https://www.tandfonline.com/doi/abs/10.1080/15434303.2017.1421955?journalCode=hlaq20},
  volume       = {15},
  year         = {2018},
  pubtype={a1}
}

@inproceedings{Minervini17_UAI,
  author       = {Minervini, P. and Demeester, Thomas and Rockt{\"a}schel, T. and Riedel, S.},
  keyword      = {IBCN},
  language     = {eng},
  booktitle = {Proc. Conference on Uncertainty in Artificial Intelligence (UAI 2017)},
  location     = {Sydney, Australia},
  title        = {Adversarial sets for regularising neural link predictors},
  year         = {2017},
  pdf = {https://arxiv.org/pdf/1707.07596},
  code = {https://github.com/uclmr/inferbeddings}
}



@article{Deboom17_spotify,
  abstract     = {The amount of content on online music streaming platforms is immense, and most users only access a tiny fraction of this content. Recommender systems are the application of choice to open up the collection to these users. Collaborative filtering has the disadvantage that it relies on explicit ratings, which are often unavailable, and generally disregards the temporal nature of music consumption. On the other hand, item co-occurrence algorithms, such as the recently introduced word2vec-based recommenders, are typically left without an effective user representation. In this paper, we present a new approach to model users through recurrent neural networks by sequentially processing consumed items, represented by any type of embeddings and other context features. This way we obtain semantically rich user representations, which capture a user's musical taste over time. Our experimental analysis on large-scale user data shows that our model can be used to predict future songs a user will likely listen to, both in the short and long term.},
  author       = {De Boom, Cedric and Agrawal, Rohan and Hansen, Samantha and Kumar, Esh and Yon, Romain and Chen, Ching-Wei and Demeester, Thomas and Dhoedt, Bart},
  issn         = {1380-7501},
  journal      = {Multimedia Tools and Applications},
  keyword      = {Recommender systems,Machine learning,Recurrent neural networks,Deep learning,Word2vec,Music information retrieval,Representation learning},
  language     = {eng},
  pages        = {23},
  publisher    = {Springer Nature},
  title        = {Large-scale user modeling with recurrent neural networks for music discovery on multiple time scales},
  url          = {https://link.springer.com/article/10.1007/s11042-017-5121-z},
  year         = {2017},
  pdf = {https://arxiv.org/pdf/1708.06520},
  pubtype={a1}
}



@inproceedings{Sterckx17_lyrics,
  author       = {Sterckx, Lucas and Naradowsky, J. and Byrne, B. and Demeester, Thomas and Develder, Chris},
  isbn         = {9781510847453},
  keyword      = {IBCN},
  booktitle = {Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP 2017)}, pages = {2074–2080},
  language     = {eng},
  location     = {Copenhagen, Denmark},
  title        = {Break it down for me : a study in automated lyric annotation},
  year         = {2017},
  abstract = {Comprehending lyrics, as found in songs and poems, can pose a challenge to human and machine readers alike. This motivates the need for systems that can understand the ambiguity and jargon found in such creative texts, and provide commentary to aid readers in reaching the correct interpretation.
We introduce the task of automated lyric annotation (ALA). Like text simplification, a goal of ALA is to rephrase the original text in a more easily understandable manner. However, in ALA the system must often include additional information to clarify niche terminology and abstract concepts. To stimulate research on this task, we release a large collection of crowdsourced annotations for song lyrics. We analyze the performance of translation and retrieval models on this task, measuring performance with both automated and human evaluation. We find that each model captures a unique type of information important to the task.},
  pdf = {https://arxiv.org/pdf/1708.03492},

}


@inproceedings{Bekoulis17_eacl,
  author       = {Bekoulis, Giannis and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
  isbn         = {978-1-510838-64-2},
  keyword      = {IBCN},
  booktitle = {Proc. 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2017)},
  language     = {eng},
  location     = {Valencia, Spain},
  title        = {Reconstructing the house from the ad: Structured prediction on real estate classifieds},
  year         = {2017},
  pdf = {http://www.aclweb.org/anthology/E17-2044},
  abstract = {In this paper, we address the (to the best of our knowledge) new problem of extracting a structured description of real estate properties from their natural language descriptions in classifieds. We survey and present several models to (a) identify important entities of a property (e.g., rooms) from classifieds and (b) structure them into a tree format, with the entities as nodes and edges representing a part-of relation. Experiments show that a graph-based system deriving the tree from an initially fully connected entity graph, outperforms a transition-based system starting from only the entity nodes, since it better reconstructs the tree.},
}

@inproceedings{Demeester16_emnlp,
  author       = {Demeester, Thomas and Rockt{\"a}schel, T. and Riedel, S.},
  booktitle    = {Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP 2016)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Austin, USA},
  pages        = {1389--1399},
  title        = {Lifted rule injection for relation embeddings},
  year         = {2016},
  pdf = {https://arxiv.org/pdf/1606.08359}
}

@inproceedings{Demeester16_akbc,
  author       = {Demeester, Thomas and Rockt{\"a}schel, T. and Riedel, S.},
  keyword      = {IBCN},
  booktitle    = {Proc. 5th Workshop on Automated Base Construction (AKBC 2016)},
  language     = {eng},
  location     = {San Diego, USA},
  title        = {Regularizing relation representations by first-order implications},
  year         = {2016},
  pdf = {https://biblio.ugent.be/publication/8541779/file/8541782.pdf}
}


@article{Deboom16_PRL,
  author       = {De Boom, Cedric and Van Canneyt, Steven and Demeester, Thomas and Dhoedt, Bart},
  issn         = {0167-8655},
  journal      = {Pattern Recognition Letters},
  keyword      = {IBCN,Natural language processing,Information storage and retrieval,Artificial intelligence,Word embeddings,Representation learning},
  language     = {eng},
  pages        = {150--156},
  publisher    = {Elsevier},
  title        = {Representation learning for very short texts using weighted word embedding aggregation},
  url          = {https://dl.acm.org/citation.cfm?id=2989415},
  volume       = {80},
  year         = {2016},
  pdf = {https://arxiv.org/pdf/1607.00570.pdf},
  pubtype={a1}
}


@article{Sterckx16_SLP,
  author       = {Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Develder, Chris},
  issn         = {0950-7051},
  journal      = {Knowledge-Based Systems},
  keyword      = {Semi-supervised learning,CONSTRUCTION,Distant supervision,Active learning,Knowledge base population,Relation extraction,IBCN},
  language     = {eng},
  pages        = {79--91},
  title        = {Knowledge base population using semantic label propagation},
  url          = {https://dl.acm.org/citation.cfm?id=2989721},
  volume       = {108},
  year         = {2016},
  month = {Sep.},
  abstract = {Training relation extractors for the purpose of automated knowledge base population requires the availability of sufficient training data. The amount of manual labeling can be significantly reduced by applying distant supervision, which generates training data by aligning large text corpora with existing knowledge bases. This typically results in a highly noisy training set, where many training sentences do not express the intended relation. In this paper, we propose to combine distant supervision with minimal human supervision by annotating features (in particular shortest dependency paths) rather than complete relation instances. Such feature labeling eliminates noise from the initial training set, resulting in a significant increase of precision at the expense of recall. We further improve on this approach by introducing the Semantic Label Propagation (SLP) method, which uses the similarity between low-dimensional representations of candidate training instances to again extend the (filtered) training set in order to increase recall while maintaining high precision. Our strategy is evaluated on an established test collection designed for knowledge base population (KBP) from the TAC KBP English slot filling task. The experimental results show that SLP leads to substantial performance gains when compared to existing approaches while requiring an almost negligible human annotation effort.},
  pdf = {https://arxiv.org/pdf/1511.06219},
  pubtype={a1}
}



@inproceedings{Deboom16_rnnworkshop,
  abstract     = {We present four training and prediction schedules from the same character-level recurrent neural network. The efficiency of these schedules is tested in terms of model effectiveness as a function of training time and amount of training data seen. We conclude that the sequence to sequence training, together with sequence to sample prediction, performs the most efficient and consistent across multiple parameter settings. We show that the choice of training and prediction schedule potentially has a considerable impact on the prediction effectiveness for a given training budget.},
  author       = {De Boom, Cedric and Leroux, Sam and Bohez, Steven and Simoens, Pieter and Demeester, Thomas and Dhoedt, Bart},
  booktitle    = {Proc. Data Efficient Machine Learning workshop},
  keyword      = {IBCN,neural networks,deep learning,efficiency,RNN,machine learning,text,characters},
  language     = {eng},
  location     = {New York, USA},
  pages        = {2},
  title        = {Efficiency Evaluation of Character-level RNN Training Schedules},
  year         = {2016},
  pdf = {https://arxiv.org/pdf/1605.02486}
}





@inproceedings{Sterckx16_emnlp,
  author       = {Sterckx, Lucas and Caragea, Cornelia and Demeester, Thomas and Develder, Chris},
  booktitle = {Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP 2016)},
  pages = {1924–-1929},
  isbn         = {978-1-5108-3154-4 },
  keyword      = {IBCN},
  location     = {Austin, USA},
  title        = {Supervised keyphrase extraction as positive unlabeled learning},
  year         = {2016},
  abstract = {The problem of noisy and unbalanced training data for supervised keyphrase extraction results from the subjectivity of keyphrase assignment, which we quantify by crowdsourcing keyphrases for news and fashion magazine articles with many annotators per document. We show that annotators exhibit substantial disagreement, meaning that single annotator data could lead to very different training sets for supervised keyphrase extractors. Thus, annotations from single authors or readers lead to noisy training data and poor extraction performance of the resulting supervised extractor. We provide a simple but effective solution to still work with such data by reweighting the importance of unlabeled candidate phrases in a two stage Positive Unlabeled Learning setting. We show that performance of trained keyphrase extractors approximates a classifier trained on articles labeled by multiple annotators, leading to higher average F1scores and better rankings of keyphrases. We apply this strategy to a variety of test collections from different backgrounds and show improvements over strong baseline models.},
  pdf = {https://biblio.ugent.be/publication/8507315/file/8507320.pdf}
}



@article{Demeester16_disagreement,
  abstract     = {Evaluation of search engines relies on assessments of search results for selected test queries, from which we would ideally like to draw conclusions in terms of relevance of the results for general (e.g., future, unknown) users. In practice however, most evaluation scenarios only allow us to conclusively determine the relevance towards the particular assessor that provided the judgments. A factor that cannot be ignored when extending conclusions made from assessors towards users, is the possible disagreement on relevance, assuming that a single gold truth label does not exist. This paper presents and analyzes the predicted relevance model (PRM), which allows predicting a particular result's relevance for a random user, based on an observed assessment and knowledge on the average disagreement between assessors. With the PRM, existing evaluation metrics designed to measure binary assessor relevance, can be transformed into more robust and effectively graded measures that evaluate relevance towards a random user. It also leads to a principled way of quantifying multiple graded or categorical relevance levels for use as gains in established graded relevance measures, such as normalized discounted cumulative gain, which nowadays often use heuristic and data-independent gain values. Given a set of test topics with graded relevance judgments, the PRM allows evaluating systems on different scenarios, such as their capability of retrieving top results, or how well they are able to filter out non-relevant ones. Its use in actual evaluation scenarios is illustrated on several information retrieval test collections.},
  author       = {Demeester, Thomas and Aly, Robin and Hiemstra, Djoerd and Dong Nguyen, Dong Nguyen and Develder, Chris},
  issn         = {1386-4564},
  journal      = {Information Retrieval},
  keyword      = {IBCN,Information retrieval evaluation,Test collections,Graded relevance assessments for information retrieval,Assessor disagreement},
  language     = {eng},
  number       = {3},
  pages        = {284--312},
  title        = {Predicting relevance based on assessor disagreement : analysis and practical applications for search evaluation},
  url          = {https://dl.acm.org/citation.cfm?id=2957577},
  volume       = {19},
  year         = {2016},
  pdf = {https://arxiv.org/pdf/1511.07237},
  pubtype={a1}
}

@inproceedings{Vandersmissen16_video,
  author       = {Vandersmissen, Baptist and Sterckx, Lucas and Demeester, Thomas and Jalalvand, Azarakhsh and De Neve, Wesley and Van de Walle, Rik},
  booktitle    = {Proc. ACM International Conference on Multimedia Retrieval (ICMR 2016)},
  isbn         = {978-1-4503-4359-6},
  keyword      = {fine-grained video annotation,deep neural networks,video retrieval},
  language     = {eng},
  location     = {New York, New York, USA},
  pages        = {409--412},
  publisher    = {ACM},
  title        = {An automated end-to-end pipeline for fine-grained video annotation using deep neural networks},
  url          = {http://dx.doi.org/10.1145/2911996.2912028},
  year         = {2016},
  pdf = {https://biblio.ugent.be/publication/8048654/file/8048655.pdf}
}


@inproceedings{Deboom15_similarity,
  abstract     = {Levering data on social media, such as Twitter and Facebook, requires information retrieval algorithms to become able to relate very short text fragments to each other. Traditional text similarity methods such as tf-idf cosine-similarity, based on word overlap, mostly fail to produce good results in this case, since word overlap is little or non-existent. Recently, distributed word representations, or word embeddings, have been shown to successfully allow words to match on the semantic level. In order to pair short text fragments - as a concatenation of separate words - an adequate distributed sentence representation is needed, in existing literature often obtained by naively combining the individual word representations. We therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching. This paper investigates the effectiveness of several such naive techniques, as well as traditional tf-idf similarity, for fragments of different lengths. Our main contribution is a first step towards a hybrid method that combines the strength of dense distributed representations - as opposed to sparse term matching - with the strength of tf-idf based methods to automatically reduce the impact of less informative terms. Our new approach outperforms the existing techniques in a toy experimental set-up, leading to the conclusion that the combination of word embeddings and tf-idf information might lead to a better model for semantic content within very short text fragments.},
  author       = {De Boom, Cedric and Van Canneyt, Steven and Bohez, Steven and Demeester, Thomas and Dhoedt, Bart},
  booktitle    = {Proc. IEEE International Conference on Data Mining Workshop (ICDMW)},
  isbn         = {978-1-4673-8493-3},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Atlantic City, USA},
  pages        = {1229--1234},
  publisher    = {IEEE},
  title        = {Learning semantic similarity for very short texts},
  url          = {http://dx.doi.org/10.1109/ICDMW.2015.86},
  year         = {2015},
}


@inproceedings{Sterckx15_TAC,
  author       = {Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Develder, Chris},
  booktitle    = {Proc. 8th Text Analysis Conference (TAC 2015)},
  language     = {eng},
  title        = {Ghent University-IBCN participation in the TAC KBP 2015 cold start slot filling task},
  year         = {2015},
  abstract = {This paper presents the system of the UGENT IBCN team for the TAC KBP 2015 cold start (slot filling variant) task. This was the team’s second participation. The slot filling system uses distant supervision to generate training data combined with feature labeling and semi-supervision, and two different types of classifiers. We show that the noise reduction step significantly improves precision, and propose an application of word embeddings for slot filling.},
}

@inproceedings{Barrio2015CIKM,
author = {Barrio, Pablo and Gravano, Luis and Develder, Chris},
title = {Ranking deep web text collections for scalable information extraction},
booktitle = {Proc. 24th ACM Int. Conf. Information and Knowledge Management (CIKM 2015)},
month = {19--23 Oct.},
year = {2015},
pages = {153--162},
address = {Melbourne, Australia},
doi = {10.1145/2806416.2806581},
abstract = {Information extraction (IE) systems discover structured in- formation from natural language text, to enable much richer querying and data mining than possible directly over the unstructured text. Unfortunately, IE is generally a com- putationally expensive process, and hence improving its ef- ficiency, so that it scales over large volumes of text, is of critical importance. State-of-the-art approaches for scaling the IE process focus on one text collection at a time. These approaches prioritize the extraction effort by learning key- word queries to identify the “useful” documents for the IE task at hand, namely, those that lead to the extraction of structured “tuples.” These approaches, however, do not at- tempt to predict which text collections are useful for the IE task—and hence merit further processing—and which ones will not contribute any useful output—and hence should be ignored altogether, for efficiency. In this paper, we focus on an especially valuable family of text sources, the so-called deep web collections, whose (remote) contents are only ac- cessible via querying. Specifically, we introduce and study techniques for ranking deep web collections for an IE task, to prioritize the extraction effort by focusing on collections with substantial numbers of useful documents for the task. We study both (adaptations of) state-of-the-art resource selec- tion strategies for distributed information retrieval, as well as IE-specific approaches. Our large-scale experimental eval- uation over realistic deep web collections, and for several different IE tasks, shows the merits and limitations of the alternative families of approaches, and provides a roadmap for addressing this critically important building block for efficient, scalable information extraction.},
}

@inproceedings{Sterckx15_www1,
  abstract     = {We explore how the unsupervised extraction of topic-related keywords benefits from combining multiple topic models. We show that averaging multiple topic models, inferred from different corpora, leads to more accurate keyphrases than when using a single topic model and other state-of-the-art techniques. The experiments confirm the intuitive idea that a prerequisite for the significant benefit of combining multiple models is that the models should be sufficiently different, i.e., they should provide distinct contexts in terms of topical word importance.},
  author       = {Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Develder, Chris},
  booktitle    = {Proc. 24th International Conference on World Wide Web (WWW 2015)},
  isbn         = {978-1-4503-3473-0},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Florence, Italy},
  pages        = {123--124},
  title        = {When topic models disagree: keyphrase extraction with muliple topic models},
  url          = {http://dx.doi.org/10.1145/2740908.2742731},
  year         = {2015},
}

@inproceedings{Sterckx15_www2,
  abstract     = {We propose an improvement on a state-of-the-art keyphrase extraction algorithm, Topical PageRank (TPR), incorporating topical information from topic models. While the original algorithm requires a random walk for each topic in the topic model being used, ours is independent of the topic model, computing but a single PageRank for each text regardless of the amount of topics in the model. This increases the speed drastically and enables it for use on large collections of text using vast topic models, while not altering performance of the original algorithm.},
  author       = {Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Develder, Chris},
  booktitle    = {Proc. 24th International Conference on World Wide Web (WWW 2015)},
  isbn         = {9781450334730},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Florence, Italy},
  pages        = {121--122},
  publisher    = {Association for Computing Machinery (ACM)},
  title        = {Topical word importance for fast keyphrase extraction},
  url          = {http://dx.doi.org/10.1145/2740908.2742730},
  year         = {2015},
}


@inproceedings{Demeester15_www,
  abstract     = {This paper presents 'FedWeb Greatest Hits', a large new test collection for research in web information retrieval. As a combination and extension of the datasets used in the TREC Federated Web Search Track, this collection opens up new research possibilities on federated web search challenges, as well as on various other problems.},
  author       = {Demeester, Thomas and Trieschnigg, Dolf and Zhou, Ke and Dong Nguyen, Dong Nguyen and Hiemstra, Djoerd},
  booktitle    = {Proc. 24th International Conference on World Wide Web (WWW 2015)},
  isbn         = {978-1-4503-3473-0},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Florence, ITALY},
  pages        = {27--28},
  title        = {FedWeb greatest hits: presenting the new test collection for federated web search},
  url          = {http://dx.doi.org/10.1145/2740908.2742755},
  year         = {2015},
}

@inproceedings{Zhou14_CIKM,
 author = {Zhou, Ke and Demeester, Thomas and Nguyen, Dong and Hiemstra, Djoerd and Trieschnigg, Dolf},
 title = {Aligning Vertical Collection Relevance with User Intent},
 booktitle = {Proc. 23rd ACM Conference on Information and Knowledge Management (CIKM 2014)},
 series = {CIKM '14},
 year = {2014},
 isbn = {978-1-4503-2598-1},
 location = {Shanghai, China},
 pages = {1915--1918},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2661829.2661941},
 doi = {10.1145/2661829.2661941},
 acmid = {2661941},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {aggregated search, evaluation, federated search, user intent, vertical relevance},
}


@inproceedings{Demeester14_WSDM,
  author       = {Demeester, Thomas and Aly, R and Hiemstra, D and Nguyen, D and Trieschnigg, D and Develder, Chris},
  booktitle    = {Proc. International Conference on Web Search and Data Mining (WSDM 2014)},
  isbn         = {9781450323512},
  keyword      = {IBCN},
  language     = {eng},
  location     = {New York, NY, USA},
  pages        = {1--10},
  title        = {Exploiting user disagreement for web search evaluation: an experimental approach},
  year         = {2014},
}

@article{Aly14_IR,
  abstract     = {A solid research path towards new information retrieval models is to further develop the theory behind existing models. A profound understanding of these models is therefore essential. In this paper, we revisit probability ranking principle (PRP)-based models, probability of relevance (PR) models, and language models, finding conceptual differences in their definition and interrelationships. The probabilistic model of the PRP has not been explicitly defined previously, but doing so leads to the formulation of two actual principles with different objectives. First, the belief probability ranking principle (BPRP), which considers uncertain relevance between known documents and the current query, and second, the popularity probability ranking principle (PPRP), which considers the probability of relevance of documents among multiple queries with the same features. Our analysis shows how some of the discussed PR models implement the BPRP or the PPRP while others do not. However, for some models the parameter estimation is challenging. Finally, language models are often presented as related to PR models. However, we find that language models differ from PR models in every aspect of a probabilistic model and the effectiveness of language models cannot be explained by the PRP.},
  author       = {Aly, R and Demeester, Thomas and Robertson, S},
  issn         = {1386-4564},
  journal      = {Information Retrieval},
  keyword      = {Language models,IBCN,INFORMATION-RETRIEVAL,Probability ranking principle,RELEVANCE,SPACE,Probabilistic models,Probability of relevance},
  language     = {eng},
  number       = {2},
  pages        = {177--201},
  title        = {Probabilistic models in IR and their relationships},
  url          = {http://dx.doi.org/10.1007/s10791-013-9226-3},
  volume       = {17},
  year         = {2014},
  pubtype={a1}
}

@inproceedings{Demeester14_TREC,
  author       = {Demeester, Thomas and Trieschnigg, Dolf and Nguyen, Dong and Zhou, Ke and Hiemstra, Djoerd},
  booktitle    = {Proc. Text Retrieval Conference (TREC 2014)},
  language     = {eng},
  location     = {Gaithersburg, USA},
  title        = {Overview of the TREC 2014 federated web search track},
  year         = {2014},
}

@inproceedings{Feys14_FIRE,
  author       = {Feys, Matthias and Demeester, Thomas and Fortuna, Bla\v{z} and Deleu, Johannes and Develder, Chris},
  booktitle    = {Proc. Forum for Information Retrieval Evaluation},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Bangalore, India},
  month = {5--7 Dec.},
  pages        = {1--4},
  title        = {On the robustness of event detection evaluation: a case study},
  year         = {2014},
  abstract = {Research on evaluation of IR systems has led to the insight that a robust evaluation strategy requires tests on a large number of events/queries. However, especially for event detection, the number of manually labeled events may be limited. In this paper we investigate how to optimize the evaluation strategy in those cases to maximize robustness. We also introduce two new vector space models for event detection that aim to incorporate bursty information of terms and compare these with existing models. Our experiments show that by using graded relevance levels we can reduce the impact of subjectivity and ambiguity of event detection evaluation. We also show that although user disagreement is significant, it has no real impact on the ranking of the results.},
}

@inproceedings{Mertens14_FIRE,
  author       = {Mertens, Laurent and Demeester, Thomas and Deleu, Johannes and Feys, Matthias and Develder, Chris},
  booktitle    = {Proc. Forum for Information Retrieval Evaluation},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Bangalore, India},
  pages        = {1--4},
  title        = {Entity linking: test collections revisited},
  year         = {2014},
  month = {5--7 Dec.},
  abstract = {This paper analyzes two important conditions that are usually taken for granted in the evaluation of information retrieval systems: the test queries should be representative for the intended application scenario, and a sufficient amount of queries are needed to robustly assess system performance, as well as discern performance differ- ences between systems. Both issues have important consequences, as studied in this paper for the specific case of Entity Linking systems. We investigate two methods for automatic query generation, and show them to have a vast impact on evaluated system perfor- mance. We further demonstrate the effect a query set’s size has on its ability to faithfully distinguish systems, and propose a method for assessing the possible impact on system performance adding a specific number of queries to the set might have.},
}

@inproceedings{Sterckx14_akbc,
  author       = {Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Develder, Chris},
  booktitle    = {Proc. 4th Workshop on Automated Knowledge Base Construction (AKBC 2014) at NIPS 2014},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Montreal, Canada},
  pages        = {1--6},
  title        = {Using active learning and semantic clustering for noise reduction in distant supervision},
  year         = {2014},
  month = {13 Dec.},
  abstract = {The use of external databases to generate training data, also known as Distant Supervision, has become an effective way to train supervised relation extractors but this approach inherently suffers from noise. In this paper we propose a method for noise reduction in distantly supervised training data, using a discriminative classifier and semantic similarity between the contexts of the training examples. We describe an active learning strategy which exploits hierarchical clustering of the candidate training samples. To further improve the effectiveness of this approach, we study the use of several methods for dimensionality reduction of the training samples. We find that semantic clustering of training data combined with cluster-based active learning allows filtering the training data, hence facilitating the creation of a clean training set for relation extraction, at a reduced manual labeling cost.},
}

@inproceedings{Feys14_TAC,
  author       = {Feys, Matthias and Sterckx, Lucas and Mertens, Laurent and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
  booktitle    = {Proc. 7th Text Analysis Conference (TAC 2014)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Gaithersburg, USA},
  pages        = {1--10},
  title        = {Ghent University-IBCN participation in TAC-KBP 2014 slot filling and cold start tasks},
  year         = {2014},
  abstract = {This paper presents the system of the UGENT IBCN team for the TAC KBP 2014 slot filling and cold start (slot filling variant) tasks. This was the team’s first participation in both tasks. The slot filling system uses distant supervision to generate training data combined with a noise reduction step, and two different types of classifiers. We show that the noise reduction step significantly improves precision, and propose an application of word embeddings for slot filling.},
}

@inproceedings{Fortuna14_event,
  author       = {Fortuna, Bla\v{z} and Demeester, Thomas and Develder, Chris},
  booktitle    = {Proc. Large-scale Online Learning and Decision Making Workshop (LSOLDM 2014)},
  month        = {10--12 Sep.},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Windsor, UK},
  title        = {Towards large-scale event detection and extraction from news},
  year         = {2014},
  abstract = {Understanding and reasoning about textual data is one of the important topics in artificial intelligence and is being addressed by various research communities, ranging from knowledge representation, over natural language processing to text mining. Each community provides a different set of often overlapping intuitions, tools and methodologies for working with text.
Event processing from news and social media can be seen as a subtopic of text understanding [1, 2, 3, 4]. It comprises different tasks, including New and Retrospective Event Discovery, Event Type Classification and Event Template Extraction.
Research on event processing requires access to annotated data covering different tasks in the event processing pipeline. Over the last decades, several datasets have been created covering event discovery and event extraction, e.g., [5, 6, 7]. These datasets are rather limited in scope. For example, they contain articles from only few selected sources, or they contain a limited number of annotated events with a high selection bias (e.g., towards larger or well defined events like natural disasters or terrorism). Using such limited datasets to evaluate solutions for the event processing tasks may lead to favoring approaches that do not work well on real-world datasets. The main reasons for these limitations are (1) limited access to data resources and (2) the required and expensive manual annotations.
The main contributions we are working towards are (1) a systematic methodology for efficiently creating a large golden standard of manually annotated events over a large corpus of news articles with a realistic distribution over the covered topics and events, and (2) a resulting annotated corpus a resulting annotated corpus of 10,000 English general news articles embedded in 31 million news articles.},
}

@inproceedings{Vancanneyt14_snow,
  author       = {Van Canneyt, Steven and Feys, Matthias and Schockaert, Steven and Demeester, Thomas and Develder, Chris and Dhoedt, Bart},
  booktitle    = {Proc. 2nd Workshop on Social News on the Web at WWW 2014 (SNOW 2014)},
  month        = {8 Apr.},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Seoul, Korea},
  pages        = {1--8},
  title        = {Detecting newsworthy topics in Twitter},
  year         = {2014},
  abstract = {The task of the SNOW 2014 Data Challenge is to mine Twit- ter streams to provide journalists a set of headlines and complementary information that summarize the most newswor- thy topics for a number of given time intervals. We propose a 4-step approach to solve this. First, a classifier is trained to determine whether a Twitter user is likely to post tweets about newsworthy stories. Second, tweets posted by these users during the time interval of interest are clustered into topics. For this clustering, the cosine similarity between a boosted tf-idf representation of the tweets is used. Third, we use a classifier to estimate the confidence that the obtained topics are newsworthy. Finally, for each obtained newswor- thy topic, a descriptive headline is generated together with relevant keywords, tweets and pictures. Experimental re- sults show the effectiveness of the proposed methodology.},
}

@inproceedings{Sterckx14_topics,
  author       = {Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Mertens, Laurent and Develder, Chris},
  booktitle    = {Proc. 36th European Conference on Information Retrieval (ECIR 2014)},
  issn         = {0302-9743},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Amsterdam, the Netherlands},
  pages        = {547--552},
  title        = {Assessing quality of unsupervised topics in song lyrics},
  volume       = {8416},
  year         = {2014},
  abstract     = {How useful are topic models based on song lyrics for applications in music information retrieval? Unsupervised topic models on text corpora are often difficult to interpret. Based on a large collection of lyrics, we investigate how well automatically generated topics are related to manual topic annotations. We propose to use the kurtosis metric to align unsupervised topics with a reference model of supervised topics. This metric is well-suited for topic assessments, as it turns out to be more strongly correlated with manual topic quality scores than existing measures for semantic coherence. We also show how it can be used for a detailed graphical topic quality assessment.}
}



@inproceedings{Demeester13_TREC,
  author       = {Demeester, Thomas and Trieschnigg, Dolf and Nguyen, Dong and Hiemstra, Djoerd},
  booktitle    = {Proc. Text Retrieval Conference (TREC 2013)},
  language     = {eng},
  location     = {Gaithersburg, USA},
  pages        = {1--11},
  title        = {Overview of the TREC 2013 federated web search track},
  year         = {2013}
}

@inproceedings{Aly13_TREC,
  author       = {Aly, Robin and Hiemstra, Djoerd and Trieschnigg, Dolf and Demeester, Thomas},
  booktitle    = {Proc. Text Retrieval Conference (TREC 2013)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Gaithersburg, USA},
  pages        = {1--6},
  title        = {Mirex and taily at TREC 2013},
  year         = {2013},
}

@inproceedings{Aly13_SIGIR,
  author       = {Aly, Robin and Hiemstra, Djoerd and Demeester, Thomas},
  booktitle    = {Proc. Special Interest Group on Information Retrieval (SIGIR 2013)},
  isbn         = {9781450320344},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Dublin, Ireland},
  pages        = {1--10},
  title        = {Taily: Shard selection using the tail of score distributions},
  year         = {2013},
}

@inproceedings{Demeester13_ECIR,
  author       = {Demeester, Thomas and Nguyen, Dong and Trieschnigg, Dolf and Develder, Chris and Hiemstra, Djoerd},
  booktitle    = {Proc. European Conference on Information Retrieval (ECIR 2013)},
  issn         = {0302-9743},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Moscow, Russia},
  pages        = {697--700},
  publisher    = {Springer},
  title        = {Snippet-based relevance predictions for federated web search},
  volume       = {7814},
  year         = {2013},
  abstract     = {How well can the relevance of a page be predicted, purely based on snippets? This would be highly useful in a Federated Web Search setting where caching large amounts of result snippets is more feasible than caching entire pages. The experiments reported in this pa- per make use of result snippets and pages from a diverse set of actual Web search engines. A linear classifier is trained to predict the snippet- based user estimate of page relevance, but also, to predict the actual page relevance, again based on snippets alone. The presented results confirm the validity of the proposed approach and provide promising insights into future result merging strategies for a Federated Web Search setting.},
}


@inproceedings{Mertens13_TAC,
  author       = {Mertens, Laurent and Demeester, Thomas and Deleu, Johannes and Develder, Chris},
  booktitle    = {Proc. Text Analysis Conference (TAC 2013)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Gaithersburg, MD, USA},
  pages        = {1--12},
  title        = {UGent participation in the TAC 2013 entity-linking task},
  year         = {2013},
  abstract     = {This article describes the system used by the
UGent-IBCN team for participating in the
Text Analysis Conference (TAC) 2013 English
Entity-Linking task. We kept the overall
rule-based workflow of our last year’s submission,
but significantly altered individual
components. Most importantly, these changes
include improved document pre-processing,
new ways of candidate selection, and completely
redesigned scoring and NIL-detection
mechanisms. Finally, we provide detailed data
of our system’s performance.}
}


@inproceedings{Mertens12_TAC,
  author       = {Mertens, Laurent and Demeester, Thomas and Deleu, Johannes and Demeester, Piet and Develder, Chris},
  booktitle    = {Proc. Text Analysis Conference (TACA 2012)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Gaithersburg, MD, USA},
  pages        = {1--12},
  title        = {UGent participation in the {TAC} 2012 entity-linking task},
  year         = {2012},
  abstract     = {This article describes in detail the system used by the UGent-IBCN team for participating in the Text Analysis Conference (TAC) 2012 Mono-Lingual Entity-Linking task. The pre- sented system is essentially rule-based, following a generic framework that is highly optimised for each label (i.e. with different rules for persons, organisations, and locations). The main contribution of this work is in identifying a number of label-specific issues and presenting simple heuristic solutions that yet allow building an efficient and effective system. These treated issues include resolving abbreviated organisation names, resolving popular nicknames, or taking into account American vs British spelling.},
}



@inproceedings{Hoang12_TREC,
  author       = {Hoang Van Duc, Thong and Demeester, Thomas and Deleu, Johannes and Demeester, Piet and Develder, Chris},
  booktitle    = {Proc. Text Retrieval Conference (TREC 2012)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Ghent, Belgium},
  pages        = {1--5},
  title        = {UGent participation in the Microblog Track 2012},
  year         = {2012},
  abstract     = {In this paper, we describe the search system, developed at Ghent University for the TREC 2012 Microblog Track in order to rank Twitter messages or ‘tweets’ from a fixed corpus in response to a number of search requests. Our system ranks the tweets based on a Logistic Regression classifier trained with data from the Microblog Track 2011. The features used for training the classifier include local tweets features, but also, query expansion and tweet expansion features, based on external Web data, which appear to significantly improve results.},
}


@inproceedings{Demeester12_AIRS,
  author       = {Demeester, Thomas and Nguyen, Dong and Trieschnigg, Dolf and Develder, Chris and Hiemstra, Djoerd},
  booktitle    = {Proc. 8th Asian Information Retrieval Societies Conference (AIRS 2012), LNCS 7675},
  issn         = {0302-9743},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Tianjin, China},
  pages        = {250--261},
  title        = {What snippets say about pages in federated web search},
  volume       = {7675},
  year         = {2012},
  month        = {17--19 Dec.},
  abstract     = {What is the likelihood that a Web page is considered relevant to a query, given the relevance assessment of the corresponding snippet? Using a new federated IR test collection that contains search results from over a hundred search engines on the internet, we are able to investigate such research questions from a global perspective. Our test collection covers the main Web search engines like Google, Yahoo!, and Bing, as well as a number of smaller search engines dedicated to multimedia, shopping, etc., and as such reﬂects a realistic Web environment. 
Using a large set of relevance assessments, we are able to investigate the connection between snippet quality and page relevance. The dataset is strongly inhomogeneous, and although the assessors’ consistency is shown to be satisfying, care is required when comparing resources. To this end, a number of probabilistic quantities, based on snippet and page relevance, are introduced and evaluated.},
}

@inproceedings{Nguyen12_CIKM,
  author       = {Nguyen, Dong and Demeester, Thomas and Trieschnigg, Dolf and Hiemstra, Djoerd},
  booktitle    = {Proc. 21st ACM Conference on Information and Knowledge Management (CIKM 2012)},
  isbn         = {9781450311564},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Maui, USA},
  pages        = {1--5},
  title        = {Federated search in the wild: the combined power of over a hundred search engines},
  year         = {2012},
}

@inproceedings{VDBossche12_DIR,
  author       = {Van Den Bossche, Bruno and Vermeulen, Brecht and Deleu, Johannes and Demeester, Thomas and Demeester, Piet},
  booktitle    = {Proc. 12th Dutch-Belgian Information Retrieval Workshop (DIR 2012)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Ghent, Belgium},
  pages        = {85--86},
  title        = {MediaHaven: multimedia asset management with integrated NER and categorization},
  year         = {2012},
}

@inproceedings{Deleu12_DIR,
  author       = {Deleu, Johannes and De Moor, An and Demeester, Thomas and Vermeulen, Brecht and Demeester, Piet},
  booktitle    = {Proc. 12th Dutch-Belgian Information Retrieval Workshop (DIR 2012)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Ghent, Belgium},
  pages        = {38--41},
  publisher    = {Ghent University, Department of Information technology},
  title        = {Named entity recognition on flemish audio-visual and news-paper archives},
  year         = {2012},
}

@inproceedings{Vandamme12_DIR,
  author       = {Vandamme, Stijn and Wauters, Tim and Demeester, Thomas and De Turck, Filip},
  booktitle    = {Proc. 12th Dutch-Belgian Information Retrieval Workshop (DIR 2012)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Ghent, Belgium},
  pages        = {34--37},
  publisher    = {Ghent University, Department of Information technology},
  title        = {Implementation and evaluation of query filtering in a role ontology-enhanced search engine},
  year         = {2012},
}

@inproceedings{Hoang12_DIR,
  author       = {Hoang Van Duc, Thong and Demeester, Thomas and Develder, Chris and Shin, Hyoseop},
  booktitle    = {Proc. 12th Dutch-Belgian Information Retrieval Workshop (DIR 2012)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Ghent, Belgium},
  pages        = {30--33},
  publisher    = {Ghent University, Department of Information technology},
  title        = {Effectiveness of learning to rank for finding user similarity in social media},
  year         = {2012},
  abstract = {This paper focuses on an automatic and accurate approach for finding similar users in social networks. Many types of social networks could benefit from such techniques, but the focus in this paper is on online photo services. The similarity between users needs to be considered on two different levels, i.e., the semantic similarity (or correspondence in tagging behavior), and the similarity in terms of social relations. In recent work, heuristic formulas were introduced for the tag commonness (TC) and the link strength (LS), with an adaptive combination scheme to describe how relevant each of these similarity aspects are for particular users, in order to define the user similarity. This paper presents an experiment, where a Learning-to-Rank approach is used to find suitable combinations of TC and LS related parameter values, hence taking into account the proficiency of users to tag their photos, and their noticeability in the online community, in order to obtain an overall user similarity. The user experiments show that the results with this learning-to-rank approach are significantly better than with a former, heuristic, approach.},
}

@inproceedings{Mertens12_DIR,
  author       = {Mertens, Laurent and Demeester, Thomas and Deleu, Johannes and Develder, Chris and Demeester, Piet},
  booktitle    = {Proc. 12th Dutch-Belgian Information Retrieval Workshop (DIR 2012)},
  keyword      = {IBCN},
  language     = {eng},
  location     = {Ghent, Belgium},
  pages        = {26--29},
  publisher    = {Ghent University, Department of Information technology},
  title        = {Context-based person identification for news collections},
  year         = {2012},
  abstract = {In modern automated information extraction systems, Named Entity Disambiguation (NED) techniques are becoming increasingly important. The ambiguity of person names leads to a decrease in the output quality of search engines. This paper presents a two-stage rule-based NED model, based on a local and global context of the mentioned persons. A number of experiments with different scoring functions are reported, as well as a specific evaluation method to estimate the efficiency of the model on a real-life data collection in an unsupervised way.},
}

@inproceedings{Aly11_ICTIR,
  abstract     = {Probability of relevance (PR) models are generally assumed to implement the Probability Ranking Principle (PRP) of IR, and recent publications claim that PR models and language models are similar. However, a careful analysis reveals two gaps in the chain of reasoning behind this statement. First, the PRP considers the relevance of particular documents, whereas PR models consider the relevance of any query-document pair. Second, unlike PR models, language models consider draws of terms and documents. We bridge the first gap by showing how the probability measure of PR models can be used to define the probabilistic model of the PRP. Furthermore, we argue that given the differences between PR models and language models, the second gap cannot be bridged at the probabilistic model level. We instead define a new PR model based on logistic regression, which has a similar score function to the one of the query likelihood model. The performance of both models is strongly correlated, hence providing a bridge for the second gap at the functional and ranking level. Understanding language models in relation with logistic regression models opens ample new research directions which we propose as future work.},
  author       = {Aly, Robin and Demeester, Thomas},
  booktitle    = {Proc. 3rd Conference on Theory of Information Retrieval (ICTIR 2011), Lecture Notes in Computer Science},
  editor       = {Amati, Giambattista and Crestani, Fabio},
  isbn         = {9783642233173},
  issn         = {0302-9743},
  keyword      = {IBCN,INFORMATION-RETRIEVAL},
  language     = {eng},
  location     = {Bertinoro, Italy},
  pages        = {164--175},
  publisher    = {Springer},
  title        = {Towards a better understanding of the relationship between probabilistic models in IR},
  url          = {http://dx.doi.org/10.1007/978-3-642-23318-0\_16},
  volume       = {6931},
  year         = {2011},
}

